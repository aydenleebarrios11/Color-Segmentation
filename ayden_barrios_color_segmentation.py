# -*- coding: utf-8 -*-
"""Ayden Barrios Color Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NtQf1qvL2Nl4ChQFbbzA0lUEMn2z9DvE
"""

import gdown
gdown.download_folder(id="18Mx2Xc9UNFZYajYu9vfmRFlFCcna5I0J", quiet=True, use_cookies=False)

gdown.download_folder(id="1Yl4_5O_ZEkz_KJVs0_vS5TrZUqMYkwr4", quiet=True, use_cookies=False)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np

train_image = mpimg.imread('/content/train_images/106.jpg')
plt.imshow(train_image)
plt.axis("off")
plt.show()

"""## Orange Ball Clustering using Single Gaussian"""

import os
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


def load_images(folder: str):
    files = [f for f in os.listdir(folder) if f.lower().endswith((".jpg", ".jpeg", ".png"))]
    files.sort()
    images = []
    for f in files:
        img = mpimg.imread(os.path.join(folder, f))
        images.append(img)
    return files, images


def extract_orange_pixels(image: np.ndarray):
    if image.ndim == 3 and image.shape[2] == 4:
        image = image[:, :, :3]
    if image.max() > 1.0:
        image = image / 255.0

    r, g, b = image[:, :, 0], image[:, :, 1], image[:, :, 2]

    primary_mask = (
        (r > 0.5)
        & (g > 0.2) & (g < 0.6)
        & (b < 0.4)
        & (r > g) & (r > b)
        & (g > b)
    )

    eps = 1e-6
    rg_ratio = r / (g + eps)
    rb_ratio = r / (b + eps)
    gb_ratio = g / (b + eps)
    ratio_mask = ((rg_ratio > 1.2) & (rg_ratio < 3.0) & (rb_ratio > 2.0) & (gb_ratio > 1.1))

    brightness = (r + g + b) / 3
    brightness_mask = (brightness > 0.3) & (brightness < 0.8)

    final_mask = primary_mask & ratio_mask & brightness_mask
    orange_pixels = image[final_mask]
    return orange_pixels, final_mask


def visualize_results(image: np.ndarray, orange_mask: np.ndarray, title: str = "Result"):
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    axes[0].imshow(image); axes[0].set_title("Original"); axes[0].axis("off")
    axes[1].imshow(orange_mask, cmap="gray"); axes[1].set_title(f"Mask ({int(np.sum(orange_mask))} px)"); axes[1].axis("off")
    overlay = image.copy()
    if image.max() <= 1.0: overlay[orange_mask] = [1, 0, 0]
    else: overlay[orange_mask] = [0, 255, 0]
    axes[2].imshow(overlay); axes[2].set_title("Green Higlight Pixels Found"); axes[2].axis("off")
    plt.suptitle(title); plt.tight_layout(); plt.show()


def collect_orange_training_pixels(train_folder: str):
    files, images = load_images(train_folder)
    all_orange = []
    used = 0
    for f, img in zip(files, images):
        opx, _ = extract_orange_pixels(img)
        if len(opx) > 0:
            all_orange.append(opx); used += 1
            print(f"  {f}: extracted {len(opx)} orange pixels")
    if len(all_orange) == 0:
        raise ValueError("No orange pixels found in training set.")
    all_orange = np.vstack(all_orange).astype(np.float32)
    print(f"Used {used}/{len(files)} images; total orange pixels: {len(all_orange)}")
    return all_orange


def fit_single_gaussian(orange_pixels: np.ndarray):
    mu = np.mean(orange_pixels, axis=0)
    Sigma = np.cov(orange_pixels.T)
    reg = max(1e-6, np.trace(Sigma) * 1e-4)
    Sigma = Sigma + np.eye(3) * reg
    det_cov = np.linalg.det(Sigma)
    if abs(det_cov) < 1e-10:
        Sigma = Sigma + np.eye(3) * 1e-4
    print(f"Single-Gaussian μ: {mu}")
    print(f"|Σ|: {np.linalg.det(Sigma):.2e}")
    return mu, Sigma


def gaussian_pdf(x: np.ndarray, mu: np.ndarray, Sigma: np.ndarray):
    d = 3
    det_cov = max(np.linalg.det(Sigma), 1e-18)
    inv_cov = np.linalg.pinv(Sigma)
    norm_const = 1.0 / np.sqrt((2 * np.pi) ** d * det_cov)
    diff = x - mu
    if diff.ndim == 1:
        maha = float(diff.T @ inv_cov @ diff)
        return norm_const * np.exp(-0.5 * maha)
    else:
        maha = np.sum((diff @ inv_cov) * diff, axis=1)
        return norm_const * np.exp(-0.5 * maha)


def set_parameters():
    threshold = 0.01
    prior = 0.5
    return threshold, prior


def classify_image_with_single_gaussian(image: np.ndarray, mu: np.ndarray, Sigma: np.ndarray, threshold: float, prior: float):
    if image.ndim == 3 and image.shape[2] == 4:
        image = image[:, :, :3]
    if image.max() > 1.0:
        image = image / 255.0
    H, W = image.shape[:2]
    X = image.reshape(-1, 3).astype(np.float32)
    likelihood = gaussian_pdf(X, mu, Sigma)
    posterior = likelihood * prior
    mask = (posterior >= threshold).reshape(H, W)
    return mask, posterior.reshape(H, W)


def run_single_gaussian(train_folder: str = "./train_images", test_folder: str = "./test_images"):
    training_pixels = collect_orange_training_pixels(train_folder)
    mu, Sigma = fit_single_gaussian(training_pixels)
    threshold, prior = set_parameters()

    train_files, train_imgs = load_images(train_folder)
    if len(train_imgs) > 0:
        mask, _ = classify_image_with_single_gaussian(train_imgs[0], mu, Sigma, threshold, prior)
        visualize_results(train_imgs[0], mask, title=f"Part1 Train sample (thr={threshold:.2e})")

    test_files, test_imgs = load_images(test_folder)
    for fname, img in zip(test_files, test_imgs):
        mask, _ = classify_image_with_single_gaussian(img, mu, Sigma, threshold, prior)
        visualize_results(img, mask, title=f"Part1 Test: {fname} (thr={threshold:.2e})")
        print(f"{fname}: orange pixels = {int(mask.sum())} / {mask.size} "
              f"({100.0*mask.sum()/mask.size:.2f}%)")

if __name__ == "__main__":
    run_single_gaussian()

"""##GMM to Cluster Pixel Colors"""

gmm_gaussian_pdf = gaussian_pdf
get_training_data_for_gmm = collect_orange_training_pixels

def trainGMM(K, train_folder="./train_images", max_iter=200, epsilon=1e-6, seed=42):
  np.random.seed(seed)
  X = get_training_data_for_gmm(train_folder)
  n, d = X.shape
  init_idx = np.random.choice(n, K, replace=False)
  means = X[init_idx].copy()
  global_cov = np.cov(X.T) + 1e-5 * np.eye(d)
  covariances = np.array([global_cov.copy() for _ in range(K)])
  scalars = np.ones(K) / K

  prev_ll = -np.inf
  for _ in range(max_iter):
    resp = np.zeros((n, K))
    for k in range(K):
      resp[:, k] = scalars[k] * gmm_gaussian_pdf(X, means[k], covariances[k])
    row_sums = resp.sum(axis=1)
    row_sums[row_sums == 0] = 1e-12
    ll = np.mean(np.log(row_sums))
    resp = resp / row_sums[:, None]

    Nk = resp.sum(axis=0)
    scalars = Nk / n
    for k in range(K):
      means[k] = (resp[:, k] @ X) / max(Nk[k], 1e-12)
      diff = X - means[k]
      covariances[k] = (diff.T @ (resp[:, k][:, None] * diff)) / max(Nk[k], 1e-12)
      covariances[k] += 1e-5 * np.eye(d)

    if abs(ll - prev_ll) < epsilon:
      break
    prev_ll = ll

  return scalars, means, covariances


def testGMM(Model_parameters, threshold, prior, test_folder="./test_images"):
  pi_vals, mu_vals, cov_vals = Model_parameters
  test_files, test_imgs = load_images(test_folder)

  cluster_parameters = []
  for fname, img in zip(test_files, test_imgs):
    if img.ndim == 3 and img.shape[2] == 4:
      img = img[:, :, :3]
    if img.max() > 1.0:
      img = img / 255.0
    h, w = img.shape[:2]
    X = img.reshape(-1, 3).astype(np.float32)

    post = np.zeros((X.shape[0], len(pi_vals)))
    for k in range(len(pi_vals)):
      post[:, k] = pi_vals[k] * gmm_gaussian_pdf(X, mu_vals[k], cov_vals[k])
    sums = post.sum(axis=1)
    sums[sums == 0] = 1e-12
    post = post / sums[:, None]

    score = post.max(axis=1) * prior
    smin, smax = score.min(), score.max()
    scores = (score - smin) / (smax - smin) if smax > smin else np.zeros_like(score)

    mask = (scores >= threshold).reshape(h, w)

    area = int(mask.sum())
    if area > 0:
      ys, xs = np.where(mask)
      centroid = (float(xs.mean()), float(ys.mean()))
    else:
      centroid = (-1.0, -1.0)

    cluster_parameters.append({"image": fname, "area": area, "centroid": centroid, "mask": mask})

  out_dir = os.path.join(test_folder, "results")
  os.makedirs(out_dir, exist_ok=True)
  for r in cluster_parameters:
    out_path = os.path.join(out_dir, r["image"].rsplit('.', 1)[0] + "_mask.png")
    mpimg.imsave(out_path, (r["mask"].astype(np.uint8) * 255), cmap='gray')

  return cluster_parameters


def measureDepth(cluster_parameters):
  areas, dists = [], []
  for item in cluster_parameters:
    area = max(1, item["area"])
    digits = ''.join(c if c.isdigit() else ' ' for c in item["image"]).split()
    if digits:
      dists.append(float(digits[0])); areas.append(area)

  if len(areas) >= 2:
    areas = np.array(areas, dtype=float)
    dists = np.array(dists, dtype=float)
    A = np.column_stack([1.0/np.sqrt(areas), np.ones_like(areas)])
    a, b = np.linalg.lstsq(A, dists, rcond=None)[0]
    return [float(a/np.sqrt(max(1, p["area"])) + b) for p in cluster_parameters]

  rel = [1.0/np.sqrt(max(1, p["area"])) for p in cluster_parameters]
  rel = np.array(rel, dtype=float)
  if rel.max() > rel.min():
    rel = (rel - rel.min()) / (rel.max() - rel.min())
    rel = 0.5 + 2.0 * rel
  return rel.tolist()


def plotGMM(Model_parameters, distance=None, train_folder="./train_images"):
  from mpl_toolkits.mplot3d import Axes3D

  os.makedirs("plots", exist_ok=True)
  pi_vals, mu_vals, cov_vals = Model_parameters
  K = len(pi_vals)

  fig = plt.figure(figsize=(10, 8))
  ax = fig.add_subplot(111, projection='3d')

  train_px = get_training_data_for_gmm(train_folder)
  step = max(1, len(train_px)//2000 + 1)
  samp = train_px[::step]
  ax.scatter(samp[:,0], samp[:,1], samp[:,2], s=6, alpha=0.4, c='orange', label='orange px')

  u = np.linspace(0, 2*np.pi, 40)
  v = np.linspace(0, np.pi, 20)
  colors = ['tab:orange','tab:blue','tab:green','tab:red','tab:purple']

  for k in range(K):
    center = mu_vals[k]; cov = cov_vals[k]
    evals, evecs = np.linalg.eigh(cov)
    radii = 2.0 * np.sqrt(np.maximum(evals, 1e-12))

    xs = np.outer(np.cos(u), np.sin(v))
    ys = np.outer(np.sin(u), np.sin(v))
    zs = np.outer(np.ones_like(u), np.cos(v))
    sphere = np.stack([xs, ys, zs], axis=-1)

    ell = sphere @ (evecs * radii) + center
    c = colors[k % len(colors)]
    ax.plot_surface(ell[:,:,0], ell[:,:,1], ell[:,:,2], alpha=0.35, color=c, rstride=2, cstride=2)
    ax.scatter(center[0], center[1], center[2], s=120, c=c, edgecolors='k',
               label=f'μ{k} (π={pi_vals[k]:.2f})')

  ax.set_xlabel('R'); ax.set_ylabel('G'); ax.set_zlabel('B')
  ax.set_title('GMM Ellipsoids in RGB')
  ax.view_init(elev=22, azim=45)
  ax.legend(loc='best')
  plt.tight_layout()
  plt.savefig("plots/ellipsoids.png", dpi=150)
  plt.show()

import numpy as np
import os

threshold = 0.1
prior = 1.0
K = 2

mode_flag = 1

train_folder = "./train_images"
test_folder  = "./test_images"
model_path   = "gmm_model.npz"

if mode_flag == 1:

  train_files, train_imgs = load_images(train_folder)
  print(f"Loaded {len(train_imgs)} training images")

  _ = collect_orange_training_pixels(train_folder)

  scalars, means, covariances = trainGMM(K, train_folder=train_folder)
  np.savez(model_path, scalars=scalars, means=means, covariances=covariances)
  Model = (scalars, means, covariances)

else:

  saved = np.load(model_path)
  scalars = saved["scalars"]; means = saved["means"]; covariances = saved["covariances"]
  Model = (scalars, means, covariances)x

cluster_parameters = testGMM(Model, threshold=threshold, prior=prior, test_folder=test_folder)
distance = measureDepth(cluster_parameters)
plotGMM(Model, distance=distance, train_folder=train_folder)

print("\n=== GMM Results ===")
for cp, d in zip(cluster_parameters, distance):
    print(f"{cp['image']}: area={cp['area']} pixels, centroid={cp['centroid']}, distance={float(d):.3f}")

plt.figure(figsize=(10, 5))
image_names = [cp['image'] for cp in cluster_parameters]
distances = [float(d) for d in distance]

plt.bar(range(len(image_names)), distances, color='blue', edgecolor='black')
plt.xticks(range(len(image_names)), image_names, rotation=45, ha='right')
plt.ylabel('Estimated Distance (units)')
plt.xlabel('Test Images')
plt.title('Bar Chart of Estimated Ball Distances')
plt.tight_layout()
plt.show()

"""## ***Report***
In the first part of this project, using a single Gaussian to detect orange. There was extracting training data images, extracting the orange off each training data image using masks of RGB and HSV, and then running a single Gaussian to detect orange in these images. In more detail, our orange pixel extraction process was done by first image normalization, RGB filtering to apply color constraints, ratio-based filtering to distinguish colors from each other, and brightness. This mask was done through trial and error with the goal of capturing as much of the ball as possible. One interesting problem faced in this masked through trial and error was that we were able to grid search to find the proper masks and threshold so that our result was the most optimal through testing on training images. After this, our single Gaussian was done after having the M step, the Gaussian PDF, and the classification step. These were textbooks, and a way to fully comprehend our algorithm was done in our last step, the visualization step, where our training images were being tested on.

In the second part of this project, we implemented a Gaussian Mixture Model to detect the orange ball and estimate its distance from the camera. The GMM approach built upon the single Gaussian foundation by using multiple Gaussian components to better capture the color variations in the orange ball. We began by implementing the EM algorithm from scratch, which alternated between the expectation step and maximization step to iteratively refine our model parameters. Our initialization strategy involved randomly selecting sample points from the extracted orange pixels to serve as initial means, while covariances were initialized using the global covariance of the training data with regularization added for numerical stability. We set K=2 components because this captured both the brighter and shadowed regions of the ball without overcomplicating the model. After training the GMM through the EM iterations, we applied the trained model to test images by computing posterior probabilities for each pixel and thresholding to create binary masks. For distance estimation, we leveraged the relationship between ball area and distance, fitting a parametric model of the form distance = a/sqrt(area) + b using least squares on the training data. The final visualization step involved plotting the GMM ellipsoids in 3D RGB space to show how the two components captured different aspects of the orange color distribution, as well as displaying the segmentation results and distance estimates for each test image.


For this project, we used RGB color space as our primary representation. The RGB space was chosen because it directly corresponds to the camera sensor output and provides clear separation for orange detection through the red, green, and blue channels. Our initialization method for the GMM involved randomly selecting K sample points from the training data as initial means, with K=2 gaussians. The covariance matrices were initialized using the global covariance of all training data with regularization added to ensure numerical stability. This initialization approach was effective because it started with actual data points that represent real orange pixels, rather than arbitrary values. The scaling factors (mixing coefficients) were initialized uniformly as 1/K, giving each component equal weight at the start. We chose K=2 because the orange ball exhibits variation under different lighting conditions and viewing angles, which can be captured by two distinct color distributions better than a single Gaussian.

GMM is better than a single Gaussian in many aspects. In this project, where we report finding the color orange, GMM proves to be able to detect more orange. Fundamentally, a single Gaussian tries to group all oranges together into one. Due to our understanding of the color orange, it is actually groups of colors that make up a certain orange, where our GMM detects red-based orange and blue-based orange. In the case of using a single Gaussian, it generalizes all the oranges into one. Single Gaussian also tries to fit all into one; however, this solution is too general. In this case, GMM actually creates multimodal models, which allow for each component to have its own mean and variance, allowing for a better fit. Another benefit of using GMM is under lighting in computer vision, different lighting allows for the color orange to change, and can optimize each component under its own conditions. In the case of using a single, the Gaussian either becomes too broad(which includes non-orange) or too narrow(which misses valid orange). In this project, using both single and GMM, single seemed to be affected by outliers a lot more than GMM. The structure of GMM only affects a component, not the whole model. In this case, if one component is failing in GMM, others can still work.


The distance estimation was performed using an inverse square root relationship between the detected ball area and distance. From the training data, we observed that ball area decreases as distance increases, following an approximate inverse square relationship. We fit a linear model of the form: distance = a/sqrt(area) + b using least squares regression on the training images where filenames indicated the ground truth distance in centimeters. For the test images, our results showed: 1.jpg detected 1036 orange pixels with estimated distance 2.71 units, 2.jpg detected 729 pixels with distance 5.32 units, 3.jpg detected 1105 pixels with distance 2.71 units, 4.jpg detected 1612 pixels with distance 4.01 units, 5.jpg detected 1001 pixels with distance 4.01 units, 6.jpg detected 678 pixels with distance 4.01 units, 7.jpg detected 687 pixels with distance 5.32 units, and 8.jpg detected 556 pixels with distance 7.93 units. The cluster segmentation successfully identified the ball region in all test images, with centroids computed from the detected pixels. The segmentation masks show clean ball detection with minimal false positives, indicating that the GMM threshold of 0.1 was well-calibrated for separating orange ball pixels from background.


The primary strength of our algorithm is its robustness to light variation with the use of the two-component GMM in order to represent the bright and shadowed regions of the orange ball. Color masking during training data extraction allows the high-quality samples required to learn the color distribution. The EM algorithm is stable under proper initialization and regularization of covariance matrices. In addition, the distance estimation model is simple but effective with only area calculation required without the need for intensive geometric calculation. The algorithm, however, is subject to several drawbacks. It greatly relies on the initial color mask for data extraction during training, so if the mask parameters are not set properly, the consequent GMM learned will be suboptimal. Also, the algorithm depends on the ball being the principal orange object in the scene and would fail if there are other orange objects. The distance estimation assumes constant ball size and camera parameters and would hence fail for other ball sizes or camera configurations. Taking a look at the test output, the algorithm did perform very well in all test images, correctly identifying the ball in each case. The distance estimates also have an intuitive pattern where smaller areas detected signify larger distances. Failure would be under very unusual lighting conditions, partial occlusion of the ball, or in environments with orange objects that would provide false positives.

"""